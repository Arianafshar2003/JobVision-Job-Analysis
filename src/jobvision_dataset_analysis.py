# -*- coding: utf-8 -*-
"""jobvision_dataset_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nAfusYIQVqHsJfClX2KHywakLLLiwtm4

# **Importing libraries**
"""

!pip install -U plotly kaleido

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from prophet import Prophet
import networkx as nx
import itertools
import plotly.graph_objects as go
import ast
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import requests
import unicodedata
import json
import ipywidgets as widgets
import os

pd.set_option('display.width', 200)
pd.set_option('display.max_columns', 50)

"""# **Data Preparation**"""

#  INITIAL OVERVIEW

# Login using e.g. `huggingface-cli login` to access this dataset
df = pd.read_csv("hf://datasets/JobVision/JobVision_Jobposts_Dataset/JobVision_Jobposts_Dataset.csv")
print(" Dataset Shape:", df.shape)
print(" Column Names:", df.columns.tolist())
print(" Data Types:", df.dtypes)
print(" First 5 Rows:")
print(df.head())

print(" Example Row for Business Understanding:")
example_row = df.iloc[0]
print(example_row.to_frame().T)

"""## Helper functions"""

def midpoint_salary(row):
    if pd.notna(row['Jobpost_MinSalary']) and pd.notna(row['Jobpost_MaxSalary']):
        return (row['Jobpost_MinSalary'] + row['Jobpost_MaxSalary']) / 2
    elif pd.notna(row['Jobpost_MinSalary']):
        return row['Jobpost_MinSalary']
    elif pd.notna(row['Jobpost_MaxSalary']):
        return row['Jobpost_MaxSalary']
    return np.nan

def parse_json_column(series, fa_key):
    """Extract FA items from JSON-like strings."""
    parsed = []
    for val in series:
        if pd.isna(val):
            parsed.append([])
        else:
            try:
                items = json.loads(val)
                parsed.append([item.get(fa_key) for item in items if fa_key in item])
            except:
                parsed.append([])
    return parsed

def safe_eval(val):
    if isinstance(val, str):
        try:
            return ast.literal_eval(val)
        except:
            return []
    elif isinstance(val, (list, tuple)):
        return val
    return []

def normalize_persian(text):
    return (text.replace("ى", "ی")
                .replace("ي", "ی")
                .replace("ك", "ک")
                .strip())

"""## Dealing with the missing values


"""

#  MISSING VALUE ANALYSIS
missing_df = df.isnull().sum().reset_index()
missing_df.columns = ['Column', 'Missing_Count']
missing_df['Missing_%'] = round(100 * missing_df['Missing_Count'] / len(df), 2)
print(" Missing Value Summary:", missing_df.sort_values(by='Missing_%', ascending=False))

plt.figure(figsize=(14,6))
sns.heatmap(df.isnull(), cmap='coolwarm', cbar=False, yticklabels=False)
plt.title("Missing Data Heatmap", fontsize=16)
plt.show()

#  HANDLE MISSING DATA

# 1. Salary: Keep NaN but create flag columns
df['Salary_Disclosed'] = df['Jobpost_MinSalary'].notnull() | df['Jobpost_MaxSalary'].notnull()

# 2. Work Type & Province: Replace NaN with 'نامشخص'
categorical_fill_unknown = [
    'Jobpost_ProvinceFa', 'Jobpost_WorkTypeFa', 'Jobpost_MainJobCategory',
    'Jobpost_PreferredGender', 'Jobpost_IndustryFa',
    'Company_ProvinceFa', 'Company_CityFa',
    'Comany_CompanyOwnershipTypesFa', 'Company_SizeFa', 'Company_ActivityTypeFa'
]
for col in categorical_fill_unknown:
    if col in df.columns:
        df[col] = df[col].fillna('نامشخص')

# 3. Booleans: Fill missing with False
boolean_cols = [
    'Jobpost_SalaryCanBeShown', 'Jobpost_RequiredRelatedExperienceInThisIndustry',
    'Jobpost_RequiredMilitaryServiceCard', 'Jobpost_IsRemote',
    'Jobpost_IsInternship', 'Jobpost_PriorityWithLocalCandidate'
]
for col in boolean_cols:
    if col in df.columns:
        df[col] = df[col].fillna(False)

# 4. Age: Replace with median if numeric
if 'Jobpost_RequiredMinAge' in df.columns:
    df['Jobpost_RequiredMinAge'] = df['Jobpost_RequiredMinAge'].fillna(df['Jobpost_RequiredMinAge'].median())
if 'Jobpost_RequiredMaxAge' in df.columns:
    df['Jobpost_RequiredMaxAge'] = df['Jobpost_RequiredMaxAge'].fillna(df['Jobpost_RequiredMaxAge'].median())

# 5. Experience: Replace NaN with 0
if 'Jobpost_RequiredExperienceYears' in df.columns:
    df['Jobpost_RequiredExperienceYears'] = df['Jobpost_RequiredExperienceYears'].fillna(0)

# 6. Skill columns: Replace NaN with empty list before parsing
df['Jobpost_LanguageSkills'] = df['Jobpost_LanguageSkills'].fillna("[]")
df['Jobpost_SoftwareSkills'] = df['Jobpost_SoftwareSkills'].fillna("[]")
df['Jobpost_AcademicFields'] = df['Jobpost_AcademicFields'].fillna("[]")

# 7. Dates: Convert to datetime and drop invalid rows
df['Activation_Date'] = pd.to_datetime(df['Jobpost_ActivationTime_YEAR_MONTH'], format='%Y-%m', errors='coerce')
df = df[df['Activation_Date'].notnull()]
df['Year'] = df['Activation_Date'].dt.year
df['Month'] = df['Activation_Date'].dt.month

#  CATEGORICAL & NUMERIC DESCRIPTION
categorical_cols = df.select_dtypes(include='object').columns
numeric_cols = df.select_dtypes(include=['int64','float64']).columns

print("Categorical Features:")
for col in categorical_cols:
    temp_series = df[col].dropna().apply(
        lambda x: str(x) if isinstance(x, (list, dict, set)) else x
    )
    print(f"{col}: {temp_series.nunique()} unique values | Sample: {temp_series.unique()[:5]}")


print("Numerical Features:")
print(df[numeric_cols].describe().T)

#  DROP UNUSED COLUMNS
drop_cols = [
    'Jobpost_SecondaryJobCategories',
    'Jobpost_CompanyWorkTimesDescription',
    'Jobpost_BenefitFa',
    'Jobpost_BenefitEn',
    'Jobpost_HasDisabilitySupport',
    'Company_IndustryFa',
    'Company_IndustryEn'
]
drop_cols += [col for col in df.columns if col.endswith('En')]
df.drop(columns=drop_cols, inplace=True, errors='ignore')

print("Columns After Dropping:", df.columns.tolist())

#  PARSE JSON-LIKE SKILL COLUMNS
def parse_json_column(series, fa_key):
    """Extract a list of FA items from JSON-like strings."""
    parsed = []
    for val in series:
        if pd.isna(val):
            parsed.append([])
        else:
            try:
                items = json.loads(val)
                skill_list = [item.get(fa_key, None) for item in items if fa_key in item]
                parsed.append(skill_list)
            except:
                parsed.append([])
    return parsed

df['Languages_List'] = parse_json_column(df['Jobpost_LanguageSkills'], 'Languages_TitleFa')
df['Software_List'] = parse_json_column(df['Jobpost_SoftwareSkills'], 'Software_TitleFa')
df['AcademicFields_List'] = parse_json_column(df['Jobpost_AcademicFields'], 'FieldType')


df['Num_Languages'] = df['Languages_List'].apply(len)
df['Num_SoftwareSkills'] = df['Software_List'].apply(len)
df['Num_AcademicFields'] = df['AcademicFields_List'].apply(len)

# Missing Data AFTER
missing_df_after = df.isnull().sum().reset_index()
missing_df_after.columns = ['Column', 'Missing_Count']
missing_df_after['Missing_%'] = round(100 * missing_df_after['Missing_Count'] / len(df), 2)

fig = px.bar(
    missing_df_after.sort_values(by='Missing_%', ascending=False),
    x='Missing_%', y='Column', orientation='h', color='Missing_%',
    title="Missing Data After Handling",
    color_continuous_scale='Blues'
)
fig.show()

plt.figure(figsize=(14,6))
sns.heatmap(df.isnull(), cmap='coolwarm', cbar=False, yticklabels=False)
plt.title("Missing Data Heatmap - After Handling", fontsize=16)
plt.show()

"""# **Market Overview – “Where are the Jobs?”**"""

# Provinces with Most Jobs
province_counts = df['Jobpost_ProvinceFa'].value_counts().reset_index()
province_counts.columns = ['Province', 'Count']
fig = px.bar(
    province_counts.head(15),
    x='Province',
    y='Count',
    color='Count',
    title='<b>پانزده استان برتر با بیشترین آگهی شغلی</b>',
    color_continuous_scale='Turbo',
    labels={"Count": "تعداد"}

)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    xaxis_title='استان',
    yaxis_title='تعداد آگهی',
    font=dict(family='IRANSansBold')
)
fig.show()

# Work Type Distribution
fig = px.pie(
    df,
    names='Jobpost_WorkTypeFa',
    title='<b>توزیع نوع کار</b>',
    hole=0.4,
    color_discrete_sequence=px.colors.qualitative.Vivid
)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    font=dict(family='IRANSansBold')
)
fig.show()

# Remote vs Onsite
remote_counts = df['Jobpost_IsRemote'].value_counts().reset_index()
remote_counts.columns = ['Remote', 'Count']
fig = px.bar(
    remote_counts,
    x='Remote',
    y='Count',
    title='<b>آگهی‌های دورکاری در مقابل حضوری</b>',
    color='Count',
    color_continuous_scale='Viridis',
    labels={"Count": "تعداد"}

)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    xaxis_title='دورکاری',
    yaxis_title='تعداد آگهی',
    font=dict(family='IRANSansBold')
)
fig.show()

# Job Posting Trends Over Time
trend_df = df.groupby(['Year','Month']).size().reset_index(name='PostCount')
trend_df['Date'] = pd.to_datetime(trend_df[['Year','Month']].assign(DAY=1))
fig = px.area(
    trend_df,
    x='Date',
    y='PostCount',
    title='<b>روند آگهی‌های شغلی در طول زمان</b>',
    color_discrete_sequence=['#00aaff']
)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    xaxis_title='تاریخ',
    yaxis_title='تعداد آگهی',
    font=dict(family='IRANSansBold')
)
fig.show()

# Salary Distribution
salary_df = df[df['Jobpost_MinSalary'].notnull() & (df['Jobpost_MinSalary'] > 0)]
fig = px.histogram(
    salary_df,
    x="Jobpost_MinSalary",
    nbins=50,
    title="<b>توزیع حداقل حقوق‌ها</b>",
    color_discrete_sequence=['#ff7f50']
)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    xaxis_title='حداقل حقوق',
    yaxis_title='تعداد آگهی',
    font=dict(family='IRANSansBold')
)
fig.show()

# Top Languages
lang_flat = pd.Series([lang for sublist in df['Languages_List'] for lang in sublist if lang])
lang_counts = lang_flat.value_counts().reset_index()
lang_counts.columns = ['Language', 'Count']
fig = px.bar(
    lang_counts.head(15),
    x='Language',
    y='Count',
    title='<b>زبان‌های برتر مورد نیاز در آگهی‌ها</b>',
    color='Count',
    color_continuous_scale='Cividis',
    labels={"Count": "تعداد"}

)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    xaxis_title='زبان',
    yaxis_title='تعداد آگهی',
    font=dict(family='IRANSansBold')
)
fig.show()

"""# **Demographics & Requirements Analysis**"""

# Experience Requirement
fig = px.histogram(
    df,
    x="Jobpost_RequiredExperienceYears",
    title="<b>تجربه کاری مورد نیاز (سال)</b>",
    color_discrete_sequence=['#6a5acd']
)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    xaxis_title='سال تجربه',
    yaxis_title='تعداد آگهی',
    font=dict(family='IRANSansBold')
)
fig.show()

# Gender Preference
fig = px.pie(
    df,
    names='Jobpost_PreferredGender',
    title='<b>ترجیح جنسیت در آگهی‌های شغلی</b>',
    hole=0.4,
    color_discrete_sequence=px.colors.qualitative.Set3
)
fig.update_layout(
    title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')),
    font=dict(family='IRANSansBold')
)
fig.show()

#  Gender Preference Across Industries
gender_industry = df.groupby(['Jobpost_IndustryFa', 'Jobpost_PreferredGender']).size().reset_index(name='count')
fig = px.bar(
    gender_industry, x='Jobpost_IndustryFa', y='count',
    color='Jobpost_PreferredGender',
    title="<b>ترجیحات جنسیتی در صنایع مختلف</b>",
    labels={"Jobpost_PreferredGender": "جنسیت"}

)
fig.update_xaxes(showticklabels=False, title="صنعت")
fig.update_yaxes(title="تعداد آگهی")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

#  Gender Preference Across Provinces
gender_location = df.groupby(['Jobpost_ProvinceFa', 'Jobpost_PreferredGender']).size().reset_index(name='count')
fig = px.bar(
    gender_location, x='Jobpost_ProvinceFa', y='count',
    color='Jobpost_PreferredGender',
    title="<b>ترجیحات جنسیتی در استان‌ها</b>",
    labels={"Jobpost_PreferredGender": "جنسیت"}

)
fig.update_xaxes(showticklabels=True, title="استان")
fig.update_yaxes(title="تعداد آگهی")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

#  Age Requirements
fig = px.histogram(df, x='Jobpost_RequiredMinAge', title="<b>توزیع حداقل سن مورد نیاز</b>")
fig.update_xaxes(title="حداقل سن")
fig.update_yaxes(title="تعداد آگهی")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

fig = px.histogram(df, x='Jobpost_RequiredMaxAge', title="<b>توزیع حداکثر سن مورد نیاز</b>")
fig.update_xaxes(title="حداکثر سن")
fig.update_yaxes(title="تعداد آگهی")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

"""# **Salary Analysis**"""

df_prov = df[df['Jobpost_ProvinceFa'] != 'خارج کشور'].copy()

prov_salary = (
    df_prov.groupby('Jobpost_ProvinceFa')['Mid_Salary']
    .median()
    .reset_index()
    .dropna(subset=['Mid_Salary'])
)
prov_salary.columns = ['Province', 'Median_Salary']

# GeoJSON
geojson_url = "https://raw.githubusercontent.com/mrunderline/iran-geojson/master/iran_geo.json"
geojson_text = requests.get(geojson_url).text.strip('\ufeff')
iran_geojson = json.loads(geojson_text)

prov_salary['Province'] = prov_salary['Province'].apply(normalize_persian)

fig_map = px.choropleth(
    prov_salary,
    geojson=iran_geojson,
    locations='Province',
    featureidkey='properties.NAME_1',
    color='Median_Salary',
    color_continuous_scale="YlGnBu",
    title="<b>میانگین حقوق استان‌ها</b>",
    labels={'Median_Salary': 'حقوق'}
)

fig_map.update_geos(fitbounds="locations", visible=False)
fig_map.update_layout(
    title=dict(
        y=0.9,
        x=0.95,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    font=dict(family='IRANSans', size=14, color='#333'),
    paper_bgcolor='white',
    plot_bgcolor='white',
    margin=dict(l=0, r=0, t=60, b=0)
)

fig_map.show()

# Filter only posts with salary info
salary_df = df[df['Salary_Disclosed']].copy()
salary_df['Avg_Salary'] = salary_df[['Jobpost_MinSalary', 'Jobpost_MaxSalary']].mean(axis=1)

#  Job Category
fig = px.box(
    salary_df, x='Jobpost_MainJobCategory', y='Avg_Salary',
    title="<b>توزیع حقوق بر اساس دسته‌بندی شغلی</b>",
    color='Jobpost_MainJobCategory',
    labels={"Jobpost_MainJobCategory": "زیرشاخه اصلی شغل"}

)
fig.update_xaxes(showticklabels=False, title="دسته‌بندی شغلی")
fig.update_yaxes(title="میانگین حقوق")
fig.update_layout(
    title=dict(
        y=0.9, x=0.85, xanchor='right', yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    font=dict(family='IRANSansBold')
)
fig.show()

#  Industry
fig = px.box(
    salary_df, x='Jobpost_IndustryFa', y='Avg_Salary',
    title="<b>توزیع حقوق بر اساس صنعت</b>",
    color='Jobpost_IndustryFa',
    labels={"Jobpost_IndustryFa": "صنعت"}

)
fig.update_xaxes(showticklabels=False, title="صنعت")
fig.update_yaxes(title="میانگین حقوق")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

#  Province
fig = px.box(
    salary_df, x='Jobpost_ProvinceFa', y='Avg_Salary',
    title="<b>توزیع حقوق بر اساس استان</b>",
    color='Jobpost_ProvinceFa',
    labels={"Jobpost_ProvinceFa": "استان"}

)
fig.update_xaxes(showticklabels=False, title="استان")
fig.update_yaxes(title="میانگین حقوق")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

#  City
fig = px.box(
    salary_df, x='Company_CityFa', y='Avg_Salary',
    title="<b>توزیع حقوق بر اساس شهر</b>",
    color='Company_CityFa',
    labels={"Company_CityFa": "شهر"}

)
fig.update_xaxes(showticklabels=False, title="شهر")
fig.update_yaxes(title="میانگین حقوق")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

#  Company Size vs Salary
fig = px.box(
    salary_df, x='Company_SizeFa', y='Avg_Salary',
    title="<b>اندازه شرکت در مقابل حقوق</b>",
    color='Company_SizeFa',
    labels={"Company_SizeFa": "اندازه شرکت"}

)
fig.update_xaxes(title="اندازه شرکت")
fig.update_yaxes(title="میانگین حقوق")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

#  Experience Years
fig = px.scatter(
    salary_df, x='Jobpost_RequiredExperienceYears', y='Avg_Salary',
    title="<b>حقوق در برابر سابقه کاری</b>", trendline="ols",
    color='Jobpost_RequiredExperienceYears',
    labels={"Jobpost_RequiredExperienceYears": "سابقه کار مورد نیاز"}

)
fig.update_xaxes(title="سال سابقه کاری")
fig.update_yaxes(title="میانگین حقوق")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

"""# **Skills Demand Analysis**"""

def extract_software_data(entry):
    """Extract (TitleEn_or_Fallback, Level) tuples from Jobpost_SoftwareSkills column."""
    skills = []

    if pd.isna(entry) or entry == "":
        return skills

    parsed = None

    if isinstance(entry, str):
        try:
            parsed = ast.literal_eval(entry)
        except:
            try:
                parsed = json.loads(entry)
            except:
                return skills
    elif isinstance(entry, list):
        parsed = entry

    if not isinstance(parsed, list):
        return skills

    for skill in parsed:
        if isinstance(skill, dict):
            title_en = (skill.get('TitleEn') or "").strip()
            title_fa = (skill.get('TitleFa') or "").strip()
            level = (skill.get('Level') or "").strip()

            title = title_en if title_en else title_fa

            if title:
                skills.append((title, level))

    return skills

# Apply
df['Software_Tuples'] = df['Jobpost_SoftwareSkills'].apply(extract_software_data)


# Flatten all entries into a single dataframe for analysis
all_skills = [item for sublist in df['Software_Tuples'] for item in sublist]
skills_df = pd.DataFrame(all_skills, columns=['Software', 'Level'])

# Frequency counts for skills
skill_counts = skills_df.groupby('Software').size().reset_index(name='Count').sort_values(by='Count', ascending=False)

# Top 20 Software Skills
custom_palette = ["#001BB7", "#0046FF", "#FF8040", "#E9E9E9"]

fig1 = px.bar(
    skill_counts.head(20),
    x='Count', y='Software',
    orientation='h',
    title="<b>بیست مهارت نرم‌افزاری با بیشترین تقاضا</b>",
    color='Count',
    color_continuous_scale=custom_palette,
    labels={"Count": "تعداد"}

)

fig1.update_layout(
    yaxis={'categoryorder': 'total ascending'},
    title=dict(
        y=0.9,
        x=0.85,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    xaxis_title="تعداد",
    yaxis_title="نرم افزار",
    font=dict(family="IRANSans", size=14)
)
fig1.show()

# Proficiency Level Distribution (Top 10 Skills)
top10_skills = skill_counts.head(10)['Software']
top10_df = skills_df[skills_df['Software'].isin(top10_skills)]
level_counts = top10_df.groupby(['Software', 'Level']).size().reset_index(name='Count')

fig2 = px.bar(
    level_counts,
    x='Count', y='Software',
    color='Level',
    title="<b>توزیع سطح مهارت برای ۱۰ مهارت برتر</b>",
    orientation='h',
    barmode='stack',
    color_discrete_sequence=px.colors.qualitative.Set2,
    labels={"Level": "سطح"}


)

fig2.update_layout(
    yaxis={'categoryorder': 'total ascending'},
    title=dict(
        y=0.9,
        x=0.85,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
        xaxis_title="تعداد",
        yaxis_title="نرم افزار",
    font=dict(family="IRANSans", size=14)
)
fig2.show()

salary_skill_records = []

for _, row in df.iterrows():
    salary = row['Mid_Salary']
    if pd.notna(salary):
        skills_data = row['Software_Tuples']
        if isinstance(skills_data, (list, tuple)):
            for item in skills_data:
                if isinstance(item, (list, tuple)) and len(item) > 0:
                    skill = str(item[0]).strip()
                    if skill:
                        salary_skill_records.append((skill, salary))

salary_skill_df = pd.DataFrame(salary_skill_records, columns=['Skill', 'Salary'])

# Filter to only popular skills
popular_skills = salary_skill_df['Skill'].value_counts()
popular_skills = popular_skills[popular_skills >= 5].index
salary_skill_df = salary_skill_df[salary_skill_df['Skill'].isin(popular_skills)]

print(f"Records for chart: {len(salary_skill_df)}")
fig_salary_skill = px.box(
    salary_skill_df,
    x='Salary',
    y='Skill',
    points='all',
    title='<b>توزیع حقوق بر اساس مهارت‌ها</b>',
    color_discrete_sequence=['#004B9B']
)

fig_salary_skill.update_traces(
    marker=dict(color='rgba(0,75,155,0.4)', size=5),
    line=dict(color='#004B9B')
)

fig_salary_skill.update_layout(
    title=dict(
        y=0.9,
        x=0.85,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    yaxis=dict(categoryorder='max ascending', title_text='مهارت'),
    xaxis_title='میانگین حقوق',
    font=dict(family='IRANSansBold'),
    paper_bgcolor='white',
    plot_bgcolor='white'
)

fig_salary_skill.show()

# Expand skills and salaries into a flat table
records = []
for _, row in df.iterrows():
    for tup in row['Software_Tuples']:
        if tup and isinstance(tup, (list, tuple)):
            skill = str(tup[0])
            salary = row['Mid_Salary']
            if pd.notna(salary):
                records.append((skill, salary))

salary_df = pd.DataFrame(records, columns=['Skill', 'Mid_Salary'])

# Compute average salary by skill
salary_comp = (
    salary_df.groupby('Skill')['Mid_Salary']
    .mean()
    .sort_values(ascending=False)
    .reset_index()
)

print("Average Midpoint Salary by Skill")
print(salary_comp.head(15))
fig = px.bar(
    salary_comp.head(15),
    x='Skill',
    y='Mid_Salary',
    title="<b>مهارت‌های با بالاترین حقوق متوسط</b>",
    labels={
        'Mid_Salary': 'میانگین حقوق متوسط',
        'Skill': 'مهارت'
    },
    text='Mid_Salary',
    color='Skill',
    color_discrete_sequence=px.colors.qualitative.Plotly
)

fig.update_traces(
    texttemplate='%{text:.0f}',
    textposition='outside'
)

fig.update_layout(
    title=dict(
        y=0.9,
        x=0.85,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    font=dict(family='IRANSans', size=14),
    paper_bgcolor='white',
    plot_bgcolor='white'
)

fig.show()

# Expand skill counts per posting per month
records = []
for _, row in df.iterrows():
    date = row['Activation_Date']
    if pd.notna(date):
        month = date.to_period('M').to_timestamp()
        skills_data = row['Software_Tuples']
        for item in skills_data:
            if isinstance(item, (list, tuple)) and len(item) > 0:
                skill = str(item[0]).strip()
                if skill:
                    records.append((month, skill))

skill_time_df = pd.DataFrame(records, columns=['Month', 'Skill'])

# Count skill frequency per month
skill_counts_df = skill_time_df.groupby(['Month', 'Skill']).size().reset_index(name='Count')

print(skill_counts_df.head())

# Top 5 skills overall
top_5_skills = skill_counts_df.groupby('Skill')['Count'].sum().nlargest(5).index
top_skill_trends = skill_counts_df[skill_counts_df['Skill'].isin(top_5_skills)]

custom_colors = ["#001BB7", "#0046FF", "#FF8040", "#E9E9E9"]

fig_trends = px.line(
    top_skill_trends,
    x='Month',
    y='Count',
    color='Skill',
    markers=True,
    title="<b>پنج مهارت با بالاترین تقاضا</b>",
    color_discrete_sequence=custom_colors,
    labels={"Skill": "مهارت"}

)

fig_trends.update_layout(
    title={
        'y': 0.9,
        'x': 0.85,
        'xanchor': 'right',
        'yanchor': 'top',

    },
    title_font=dict(size=24, family='IRANSansBold'),
    xaxis_title="ماه",
    yaxis_title="تعداد آگهی‌های شغلی",
    hovermode='x unified',
    font=dict(family="IRANSans", size=14)
)

fig_trends.show()

#  Insights
print("Business Insights")
if not skill_counts.empty:
    top_skill, top_count = skill_counts.iloc[0]
    second_skill, second_count = skill_counts.iloc[1]
    print(f" '{top_skill}' is the most in-demand software skill, appearing in {top_count} job posts.")
    print(f" The second most requested software is '{second_skill}' with {second_count} mentions.")

    most_common_level = skills_df['Level'].value_counts().idxmax()
    print(f" Most common proficiency level overall: '{most_common_level}'.")

# Build co-occurrence pairs
skill_lists = df['Software_Tuples'].apply(lambda x: [s[0] for s in x if len(s) > 0])

# Count co-occurrence frequencies
co_occurrence = {}
for skills in skill_lists:
    unique_skills = list(set(skills))
    if len(unique_skills) > 1:
        for combo in itertools.combinations(unique_skills, 2):
            combo = tuple(sorted(combo))
            co_occurrence[combo] = co_occurrence.get(combo, 0) + 1

# Convert to list and keep only top connections
edges_df = pd.DataFrame([(a, b, w) for (a, b), w in co_occurrence.items()],
                        columns=['Skill1', 'Skill2', 'Weight'])
edges_df = edges_df[edges_df['Weight'] >= edges_df['Weight'].quantile(0.75)]

# Create a graph
G = nx.Graph()
for _, row in edges_df.iterrows():
    G.add_edge(row['Skill1'], row['Skill2'], weight=row['Weight'])

# Position using spring layout
pos = nx.spring_layout(G, k=0.5, seed=42)

# Plotly scatter for network
edge_x, edge_y = [], []
for edge in G.edges():
    x0, y0 = pos[edge[0]]
    x1, y1 = pos[edge[1]]
    edge_x.extend([x0, x1, None])
    edge_y.extend([y0, y1, None])

edge_trace = go.Scatter(
    x=edge_x, y=edge_y,
    line=dict(width=0.5, color='gray'),
    hoverinfo='none',
    mode='lines')

node_x, node_y, node_text, node_size = [], [], [], []
for node in G.nodes():
    x, y = pos[node]
    node_x.append(x)
    node_y.append(y)
    node_text.append(node)
    node_size.append(len(list(G.neighbors(node))) * 5 + 10)

node_trace = go.Scatter(
    x=node_x, y=node_y,
    mode='markers+text',
    text=node_text,
    textposition="bottom center",
    hoverinfo='text',
    marker=dict(
        showscale=True,
        colorscale='YlGnBu',
        reversescale=True,
        color=node_size,
        size=node_size,
        colorbar=dict(
            thickness=15,
            title='Skill Connection Strength',


        ),
        line_width=2))

fig_network = go.Figure(
    data=[edge_trace, node_trace],
    layout=go.Layout(
        title=dict(
            text='شبکه لینک مهارت‌ها',
            y=0.9,
            x=0.83,
            xanchor='right',
            yanchor='top',
            font=dict(family='IRANSansBold', size=24)
        ),
        showlegend=False,
        hovermode='closest',
        margin=dict(b=40, l=60, r=40, t=80),
        annotations=[dict(
            text="هر گره نشان‌دهنده یک مهارت است<br>یال‌ها بیانگر هم‌وقوعی در آگهی‌های شغلی هستند",
            showarrow=False,
            xref="paper", yref="paper",
            x=0, y=-0.08,
            xanchor='left',
            font=dict(family='IRANSans', size=14, color='#444')
        )],
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        paper_bgcolor="white",
        plot_bgcolor="white"
    )
)

fig_network.show()

# GEOGRAPHIC + INDUSTRY DEEP-DIVE
print("=== Geographic + Industry Deep-Dive (Updated) ===")

# Province Demand
province_demand = df['Jobpost_ProvinceFa'].value_counts().reset_index()
province_demand.columns = ['Province','Count']

geojson_url = "https://raw.githubusercontent.com/mrunderline/iran-geojson/master/iran_geo.json"
iran_geojson = json.loads(requests.get(geojson_url).text.strip('\ufeff'))

# Choropleth Map: Job Demand per Province
fig_prov_demand = px.choropleth(
    province_demand,
    geojson=iran_geojson,
    locations='Province',
    featureidkey='properties.NAME_1',
    color='Count',
    color_continuous_scale="YlOrRd",  # More vibrant colors
    range_color=(0, province_demand['Count'].max()),
    labels={'Count':'تعداد آگهی'},
    title="<b>توزیع آگهی‌ها در استان‌ها</b>"
)
fig_prov_demand.update_geos(fitbounds="locations", visible=False)
fig_prov_demand.update_layout(
    title=dict(y=0.95, x=0.5, xanchor='center', font=dict(size=24, family='IRANSansBold'))
)
fig_prov_demand.show()

# TOP SOFTWARE SKILLS PER PROVINCE (Based on skill_counts_df logic)

# Build Province + Software records (same logic as skill_time_df but with Province)
records = []
for _, row in df.iterrows():
    prov = row['Jobpost_ProvinceFa']
    skills_data = row['Software_Tuples']  # already parsed as software only
    if isinstance(skills_data, (list, tuple)):
        for item in skills_data:
            if isinstance(item, (list, tuple)) and len(item) > 0:
                skill = str(item[0]).strip()
                if skill:
                    records.append((prov, skill))

prov_skill_df = pd.DataFrame(records, columns=['Province', 'Skill'])

# Filter top 10 provinces by total postings
province_demand = prov_skill_df['Province'].value_counts().reset_index()
province_demand.columns = ['Province','Count']
top_provs = province_demand.head(10)['Province']

# Keep only top provinces
prov_skill_top = prov_skill_df[prov_skill_df['Province'].isin(top_provs)]

# Compute top 10 skills overall (software only)
top_10_skills = (
    prov_skill_top['Skill']
    .value_counts()
    .nlargest(10)
    .index
)

# Replace other skills with "سایر مهارت‌ها"
prov_skill_top.loc[~prov_skill_top['Skill'].isin(top_10_skills), 'Skill'] = "سایر مهارت‌ها"

# Count by province & skill
prov_skill_ranked = prov_skill_top.groupby(['Province','Skill']).size().reset_index(name='Count')

# Keep province order same as in province_demand
prov_skill_ranked['Province'] = pd.Categorical(
    prov_skill_ranked['Province'],
    categories=top_provs,
    ordered=True
)

# Plot stacked bar
fig_prov_skills = px.bar(
    prov_skill_ranked,
    x='Province', y='Count', color='Skill',
    title="<b>مهارت های برتر در استان‌ های منتخب</b>",
    barmode='stack',
    color_discrete_sequence=px.colors.qualitative.Set3
)
fig_prov_skills.update_layout(
    title=dict(y=0.95, x=0.5, xanchor='center', font=dict(size=24, family='IRANSansBold')),
    xaxis_title="استان",
    yaxis_title="تعداد آگهی",
    legend_title="مهارت"
)
fig_prov_skills.show()

"""# **Industry Analysis**"""

industry_counts_df = (
    df.groupby([df['Activation_Date'].dt.to_period('M').dt.to_timestamp(), 'Jobpost_IndustryFa'])
      .size()
      .reset_index(name='Count')
      .rename(columns={'Activation_Date': 'Month'})
)

top_5_industries = industry_counts_df.groupby('Jobpost_IndustryFa')['Count'].sum().nlargest(5).index
top_industry_trends = industry_counts_df[industry_counts_df['Jobpost_IndustryFa'].isin(top_5_industries)]

custom_colors_industry = ["#FF5722", "#FFC107", "#009688", "#8BC34A", "#9C27B0"]

fig_industry_trends = px.line(
    top_industry_trends,
    x='Month',
    y='Count',
    color='Jobpost_IndustryFa',
    markers=True,
    title="<b>پنج صنعت با بالاترین تقاضا</b>",
    color_discrete_sequence=custom_colors_industry,
    labels={"Jobpost_IndustryFa": "صنعت"}
)

fig_industry_trends.update_layout(
    title={
        'y': 0.9,
        'x': 0.85,
        'xanchor': 'right',
        'yanchor': 'top',
    },
    title_font=dict(size=24, family='IRANSansBold'),
    xaxis_title="ماه",
    yaxis_title="تعداد آگهی‌های شغلی",
    hovermode='x unified',
    font=dict(family="IRANSans", size=14)
)

fig_industry_trends.show()

#  Remote Job Trends
remote_industry = df.groupby(['Jobpost_IndustryFa', 'Jobpost_IsRemote']).size().reset_index(name='count')
fig = px.bar(
    remote_industry, x='Jobpost_IndustryFa', y='count',
    color='Jobpost_IsRemote',
    title="<b>روند آگهی‌های دورکار بر اساس صنعت</b>",
    labels={"Jobpost_IsRemote": "نوع کار"}

)
fig.update_xaxes(showticklabels=False, title="صنعت")
fig.update_yaxes(title="تعداد آگهی")
fig.update_layout(title=dict(y=0.9, x=0.85, xanchor='right', yanchor='top', font=dict(size=24, family='IRANSansBold')))
fig.show()

"""# **Growth & Strategic Insights**"""

# Forecasting the NO 1 top demanded skill
skill_to_forecast = 'Microsoft Excel'
df_forecast = skill_counts_df[skill_counts_df['Skill'] == skill_to_forecast][['Month', 'Count']]

df_forecast = df_forecast.rename(columns={'Month': 'ds', 'Count': 'y'})

model = Prophet(interval_width=0.95)
model.fit(df_forecast)

future = model.make_future_dataframe(periods=12, freq='ME')
forecast = model.predict(future)

fig_forecast = go.Figure()

# Actual observed demand
fig_forecast.add_trace(go.Scatter(
    x=df_forecast['ds'],
    y=df_forecast['y'],
    mode='lines+markers',
    name='Historical'
))

# Forecast
fig_forecast.add_trace(go.Scatter(
    x=forecast['ds'],
    y=forecast['yhat'],
    mode='lines',
    name='Forecast',
    line=dict(color='blue', dash='dash')
))

# Confidence interval
fig_forecast.add_trace(go.Scatter(
    x=list(forecast['ds']) + list(forecast['ds'])[::-1],
    y=list(forecast['yhat_upper']) + list(forecast['yhat_lower'])[::-1],
    fill='toself',
    fillcolor='rgba(0,0,255,0.1)',
    line=dict(color='rgba(255,255,255,0)'),
    name='Confidence Interval'
))

fig_forecast.update_layout(
    title=dict(
        text=f"{skill_to_forecast} پیش‌بینی تقاضا برای ",
        y=0.9,
        x=0.85,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    xaxis_title="ماه",
    yaxis_title="تعداد آگهی‌های شغلی",
    hovermode='x unified',
    font=dict(family='IRANSans')
)

df['Activation_Date'] = pd.to_datetime(df['Activation_Date'], errors='coerce')

# Flatten skills and salaries
records = []
for _, row in df.iterrows():
    if pd.notna(row['Mid_Salary']) and row['Software_Tuples']:
        for tup in row['Software_Tuples']:
            if tup and isinstance(tup, (list, tuple)):
                skill = str(tup[0])
                records.append({
                    'Skill': skill,
                    'Mid_Salary': float(row['Mid_Salary']),
                    'Month': row['Activation_Date'].to_period('M').to_timestamp()
                })

skill_salary_df = pd.DataFrame(records)

# Average salary by skill
salary_df = (
    skill_salary_df.groupby('Skill')['Mid_Salary']
    .mean()
    .reset_index()
    .rename(columns={'Mid_Salary': 'Avg_Salary'})
)

monthly_counts = (
    skill_salary_df.groupby(['Month', 'Skill']).size()
    .reset_index(name='Count')
)

# Pivot for month-over-month growth (%) calculation
pivot_df = monthly_counts.pivot(index='Month', columns='Skill', values='Count').fillna(0)
mom_growth_df = pivot_df.pct_change() * 100
recent_growth = mom_growth_df.tail(3).mean().reset_index()
recent_growth.columns = ['Skill', 'Avg_MoM_Growth_%']

# Filter out rare skills (to remove INF/noise)
MIN_TOTAL_POSTS = 10
MIN_MONTHS = 3

skill_totals = skill_salary_df.groupby('Skill').size().reset_index(name='Total_Posts')
skill_months = skill_salary_df.groupby('Skill')['Month'].nunique().reset_index(name='Months_Appeared')

valid_skills = skill_totals.merge(skill_months, on='Skill')
valid_skills = valid_skills[
    (valid_skills['Total_Posts'] >= MIN_TOTAL_POSTS) &
    (valid_skills['Months_Appeared'] >= MIN_MONTHS)]['Skill']

# Established stable skills
recent_growth_stable = recent_growth[recent_growth['Skill'].isin(valid_skills)]
salary_df_stable = salary_df[salary_df['Skill'].isin(valid_skills)]

merged_df_stable = salary_df_stable.merge(recent_growth_stable, on='Skill', how='inner')
merged_df_stable = merged_df_stable.replace([np.inf, -np.inf], np.nan).dropna(subset=['Avg_MoM_Growth_%'])
merged_df_stable = merged_df_stable.sort_values(by=['Avg_MoM_Growth_%', 'Avg_Salary'], ascending=False)

emerging_skills = recent_growth[~recent_growth['Skill'].isin(valid_skills)]
emerging_skills = emerging_skills.replace([np.inf, -np.inf], np.nan).dropna(subset=['Avg_MoM_Growth_%'])
emerging_skills = emerging_skills.sort_values(by='Avg_MoM_Growth_%', ascending=False)

print("Top High-Growth, High-Pay Established Skills")
print(merged_df_stable.head(15))

print("New Emerging Skills")
print(emerging_skills.head(15))

# Merge with growth
df_cluster = salary_df.merge(recent_growth, on='Skill', how='inner')

# Remove inf/NaN
df_cluster = df_cluster.replace([np.inf, -np.inf], np.nan).dropna(subset=['Avg_Salary', 'Avg_MoM_Growth_%'])

# log-transform salary to reduce skew
df_cluster['Log_Avg_Salary'] = np.log1p(df_cluster['Avg_Salary'])

# SCALING
features = df_cluster[['Log_Avg_Salary', 'Avg_MoM_Growth_%']].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(features)

# CLUSTERING (choose K=4 for interpretability)
k = 4
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
df_cluster['Cluster'] = kmeans.fit_predict(X_scaled)

cluster_summary = df_cluster.groupby('Cluster').agg(
    Avg_Salary=('Avg_Salary', 'mean'),
    Avg_Growth=('Avg_MoM_Growth_%', 'mean'),
    Count_Skills=('Skill', 'count')
).reset_index()

print("Cluster Summary")
print(cluster_summary)

fig = px.scatter(
    df_cluster,
    x='Avg_MoM_Growth_%',
    y='Avg_Salary',
    color='Cluster',
    hover_data=['Skill'],
    title='<b>خوشه‌بندی: حقوق در برابر رشد</b>',
    labels={
        'Avg_MoM_Growth_%': 'نرخ رشد ماهانه (%)',
        'Avg_Salary': 'میانگین حقوق ماهانه',
        'Cluster': 'خوشه'
    },
    color_discrete_sequence=px.colors.qualitative.Plotly
)

fig.update_layout(
    title=dict(
        y=0.9,
        x=0.95,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    legend=dict(
        x=1, xanchor='right', y=1,
        font=dict(family='IRANSans', size=14, color='#333')
    ),
    font=dict(family='IRANSans', size=14, color='#333'),
    paper_bgcolor='white',
    plot_bgcolor='white'
)

fig.show()

# Salary vs Growth Quadrant Plot

salary_median = df_cluster['Avg_Salary'].median()
growth_median = df_cluster['Avg_MoM_Growth_%'].median()

# Classify points into quadrants
def classify_quadrant(row):
    if row['Avg_Salary'] >= salary_median and row['Avg_MoM_Growth_%'] >= growth_median:
        return "حقوق بالا / رشد بالا"
    elif row['Avg_Salary'] >= salary_median:
        return "حقوق بالا / رشد پایین"
    elif row['Avg_MoM_Growth_%'] >= growth_median:
        return "حقوق پایین / رشد بالا"
    else:
        return "حقوق پایین / رشد پایین"

df_cluster['Quadrant'] = df_cluster.apply(classify_quadrant, axis=1)

fig_quadrant = px.scatter(
    df_cluster,
    x='Avg_MoM_Growth_%',
    y='Avg_Salary',
    color='Quadrant',
    hover_data=['Skill'],
    title="<b> حقوق در برابر رشد مهارت‌ها</b>",
    labels={
        'Avg_MoM_Growth_%': 'نرخ رشد ماهانه (%)',
        'Avg_Salary': 'میانگین حقوق ماهانه',
        'Quadrant': 'چهار ربع'
    },
    color_discrete_sequence=px.colors.qualitative.Plotly
)

# Median lines
fig_quadrant.add_vline(
    x=growth_median, line_dash="dash", line_color="red", opacity=0.6
)
fig_quadrant.add_hline(
    y=salary_median, line_dash="dash", line_color="red", opacity=0.6
)

# Layout styling
fig_quadrant.update_layout(
    title=dict(
        y=0.9,
        x=0.95,
        xanchor='right',
        yanchor='top',
        font=dict(size=24, family='IRANSansBold')
    ),
    font=dict(family='IRANSans', size=14, color='#333'),
    legend=dict(
        x=1, xanchor='right', y=1,
        font=dict(family='IRANSans', size=14, color='#333')
    ),
    paper_bgcolor='white',
    plot_bgcolor='white',
    xaxis=dict(
        showgrid=True,
        gridcolor='rgba(200,200,200,0.2)',
        title_font=dict(size=16, family='IRANSans', color='#333'),
        tickfont=dict(size=14, family='IRANSans', color='#333')
    ),
    yaxis=dict(
        showgrid=True,
        gridcolor='rgba(200,200,200,0.2)',
        title_font=dict(size=16, family='IRANSans', color='#333'),
        tickfont=dict(size=14, family='IRANSans', color='#333')
    )
)

fig_quadrant.show()

# Province Salary Heatmap (Plotly Choropleth)